configuraiton

2020年5月14日
18:48

Broker level 参数在${KAFKA_HOME}/config/server.properties中的配置
	1. Kafka的data目录是存储Kafka的数据文件的目录，是在
	log.dirs=/data/kafka_data1, /data/kafka_data2, /data/kafka_data3
	
	Kafka的logs目录是在${KAFKA_HOME}/bin/kafka-run-class.sh中修改
	
	if [ "x$LOG_DIR" = "x" ]; then
	# LOG_DIR="$base_dir/logs"
	LOG_DIR="/data/kafka_logs"
	fi


	2. Zookeeper 设置
	Zookeeper.connect = zk1:2181,zk2:2181,zk3:2181
	
	多个kafka集群共享一个zookeeper
	kafa集群kafka1
           Zookeeper.connect = zk1:2181,zk2:2181,zk3:2181/kafka1
     kafa集群kafka2
     Zookeeper.connect = zk1:2181,zk2:2181,zk3:2181/kafka2


	3. 与Broker连接相关
	Listeners
	Advertised.listeners
	Listener.security.protocol.map
	
	4. topic管理相关
	Auto.create.topics.enable = false
	Unclean.leader.election.enable = false
	Auto.leader.rebalance.enable = false //定期重选取跟Broker上的leader数量的比例有关。
	比例是leader.imbalance.per.broker.percentage控制，默认是10%。例如，一个Broker上有10个分区，有2个分区的leader不是preferred leader就会触发
	
	5. 数据留存
	Log.retention.ms|minutes|hours
	Log.retention.bytes
	Messsage.max.bytes 默认不到1MB
	
	6. Topic level参数
	Log.Retention.ms
	Topic level 的 修改Message.max.bytes 同时需要修改 broker 的replica.fetch.max.bytes, 还要修改 consumer端fetch.message.max.bytes
	
	两种方式设置：
	kafka-topics.sh --config
	Kafka-config.sh --config
     
7. JVM参数
	KAFKA_HEAP_OPTS
	KAFKA_JVM_PERFORMANCE_OPTS
	
	Export KAFKA_HEAP_OPTS=--Xms6g
	Export KAFKA_JVM_PERFORMANCE_OPTS=-server -XX:UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
	Bin/kafka-server-start.sh config/server.properties

	8. 操作系统参数
	修改/etc/sysctl.conf
	
	文件描述符限制
     Ulimit -n 100000
     
           /proc/KAFKA_BROKER_PID/limits 中的max open file
	文件系统类型 
           XFS, ZFS
	The Linux kernel parameter,VM.Swappiness 配置为1
	提交时间（pagecahce Flush落盘时间）
           vm.dirty_ratio默认5秒，可以适当加大这个数值，提高性能 




Mirror Maker

2020年7月1日
10:58

通过从Source Cluster消费消息，然后将消息生产到Target Cluster，即普通的消息生产和消费。用户只要通过简单的consumer配置和producer配置，启动Mirror，就可以实现准实时的数据同步。


MM2 
https://cloud.tencent.com/developer/article/1530716








Deep Dive

2020年8月29日
11:28

Rao jun talk

2020年8月29日
11:28

https://www.youtube.com/watch?v=li2aowPnezA

Fail over

2020年8月29日
14:39

如果副本坏掉，kafka会新建副本，会从leader同步新的数据给新建副本。但是如果坏掉的盘是leader副本所在的盘并且其他副本没有来得及从坏掉的leader分区同步最新数据，重新选举leader后数据会丢失。


队列重新消费
	1. Offset 和消费后的结果一起保存在业务系统中
	2. 使用 kafka事务

动态增加分区，原有分区的数据不会迁移到新的分区。已有数据会一直躺在原有分区




blogs

2020年8月29日
15:08

https://www.cnblogs.com/huxi2b

performance

2020年8月29日
15:36

Partition


Page cache


sendfile zero copy


Disk sequential IO write


Performance Configuration

https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/kafka_system_level_broker_tuning.html#file_descriptor_limits

Zookeeper 

2020年8月31日
19:13

Kafka uses Zookeeper to store metadata information about topics, partitions, brokers and system coordination (such as membership statuses). 

来自 <https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/kafka_zookeeper_tuning.html> 


• zookeeper.session.timeout.ms is a setting for Kafka that specifies how long Zookeeper shall wait for heartbeat messages before it considers the client (the Kafka broker) unavailable. If this happens, metadata information about partition leadership owned by the broker will be reassigned. If this setting is too high, then it might take a long time for the system to detect a broker failure. On the other hand, if it is set to too small, it might result in frequent leadership reassignments.
• jute.maxbuffer is a crucial Java system property for both Kafka and Zookeeper. It controls the maximum size of the data a znode can contain. The default value, one megabyte, might be increased for certain production use cases.
• There are cases where Zookeeper can require more connections. In those cases, it is recommended to increase the maxClientCnxns parameter in Zookeeper.

来自 <https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/kafka_zookeeper_tuning.html> 



Kafka 事务

2020年12月13日
19:37
